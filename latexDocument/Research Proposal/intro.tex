\section{Introduction}
Service robots are slowly becoming more popular, mostly small robots with limited functionality like vacuum cleaner robots. Bigger service robots that could help in a household environment are still much in development. 
These service robots need to be able to perform many complex tasks, in all kinds of environments, while doing them safely by not colliding with objects, humans and itself.   
Tasks like navigating, speech recognition, following/recognizing humans, object detection/recognition and manipulation are all important parts for a service robot, 
and these tasks are tested in competitions like the RoboCup \cite{robocup} and RoCKin \cite{rockin}. The difficulty in programming these robots is that they need to operate in all kinds of different environments, no household is the same, 
and this makes it hard to make sure that the robot can operate safely and correctly in situations that is has never seen before. This means that the robot needs to have intelligent behaviour so it can cope with any environment it encounters. \\
In this project we will focus on the manipulation and perception part of a service robot by making use of reinforcement learning so that the robot has learned how to grasp an object that it has seen with its camera.  
Common used approaches for grasping objects with service robots are currently by using simple cartesian control, or by making use of a planner that creates a path for the arm to traverse so it can grasp an object, 
like MoveIt \footnote{MoveIt: \url{http://moveit.ros.org}} which uses the Open Motion Planning Library \cite{ompl} that has many sampling based motion planning algorithms. 
The downside of using a planner is that it requires to make new calculations every time it needs to grasp an object, where sometimes it can not find a valid plan, or it takes too long to find a valid plan
for the arm to move by. \\
Learning complex behaviour requires lots of iterations, performing this on a real robot is not always preferred, specially in its initial exploration stages where movements are random. 
While the authors of \cite{gu2016deep} show a way of reducing the learning time by using multiple robots to train the same network, they have to put limits on the movements of the robots in order for it to be safe. 
They show a way of using N amounts of robots to train, but this is not always a good solution because you need to have N amount of robots available, which can be quite costly. Although the authors used simulation, they however do 
not train in simulation and then use the network on the real robot. This is however something that we will try in this project, because we do not have multiple robot arms available, nor do we want to risk damaging the hardware during training. \\
While robotic manipulation is a very complex task, we humans are capable of performing very complex manipulation tasks. Perhaps we can take inspiration from research done on human arm motion and grasping to improve learning with a robot arm.
The authors of \cite{abend1982human} have shown that when we move our hand from one position to another position the velocity of our hand and joints create bell shapes. We could potentially use this information to learn 
faster and smoother movements of the end effector. \\
Another aspect is the actual grasping of an object, the authors of \cite{feix2014analysis} have done an analysis of human grasping and show that object types have specific grasping techniques associated with them. Although we have a 
much simpler grasp actuator on our robot, only two fingers, we can use the information on how to grasp certain object types to learn how to approach an object for faster and better grasping performance.  \\
Since the real world is complex a robot needs to be able to perform grasping tasks in an always changing world. It will have to work in an environment that is has not seen before. Instead of having an algorithm that calculates
the best way to grasp an object in an ever changing environment, it is better to learn how to grasp, and be able to apply this learned behaviour in a complex environment. Although for this project we will focus on learning 
how to grasp an object, it will not focus on a complex environment. In order to learn grasping we need to start simple first and show that it works in the real world. We will limit our grasping to objects that are actually possible 
to grasp with our two finger end effector, the objects can be complex in shape but it should be possible for our arm to actually pick up the object. We will use Reinforcement Learning with an actor-critic network for the learning 
of the control network, and make use of Convolution Neural Networks (CNN) \cite{cnn} for the perception of the environment, locating the object. 




% Version 3 additions:
  % Add human velocities. *
  % Add google real robot training *
  % Change simple objects to complex objects

% about fast grasping planning
% Stuckler, J., Ste ens, R., Holz, D., Behnke, S.:  Ecient 3D object perception and
%grasp planning for mobile manipulation in domestic environments.  Robotics and
%Autonomous Systems
%61
%(2013) 1106{1115


%For the perception part we only focus on object detection and localization, for the manupulation we assume to only pick up objects that are 
%are easy to pick up, objects that have a basic geometric shape like a box or cylinder (e.g. a coca-cola can or a small bottle). 
%
% - Two methods, simple cartesian control, complex angular control with planning. \\
% - Arm should learn how to grasp objects.  \\
% - Important that not only work in simulation but also on real arm, real world. \\
 
% - Reinforcement learning, continues action space, Cacla, google's DDPG. \\
% - 



%-Research question: Is it possible for a robotic arm to grasp an object by using reinforcement learning?
%  - Which architecture gives the best results for grasping an object?
